# GEMM Performance-Analyse: Alte vs. Neue Implementierung

**Testsystem:** macOS ARM64 (Apple Silicon), OpenMP/ARM NEON Fallback
**Compiler:** `-c opt` (Release-Build)
**Datum:** 22. Februar 2026

## Zusammenfassung

Die neue GEMM-Implementierung mit Transpose-Flags zeigt **signifikante Geschwindigkeitsvorteile** bei Backprop-Mustern mit Transposen, w√§hrend Standard-Multiplikation (NN) gleich schnell bleibt.

---

## Detaillierte Ergebnisse

### 1. Standard Matrix-Multiplikation (Baseline A √ó B, kein Transpose)

| Gr√∂√üe       | Zeit (ns)   | Modus    | Anmerkung               |
| ----------- | ----------- | -------- | ----------------------- |
| 64√ó64√ó64    | 295,402     | Baseline | Identisch (GEMM intern) |
| 128√ó128√ó128 | 2,375,073   | Baseline | Identisch (GEMM intern) |
| 256√ó256√ó256 | 21,606,111  | Baseline | Identisch (GEMM intern) |
| 512√ó512√ó512 | 175,248,000 | Baseline | Identisch (GEMM intern) |

**Fazit:** Keine Regression ‚Äì `sm_multiply()` nutzt intern `sm_gemm()` mit identischer Performance.

---

### 2. Backprop-Muster: dW = X^T √ó dY (Transpose auf linker Matrix)

| Gr√∂√üe (Batch√óIn√óOut) | ALT (ns)    | NEU (ns)    | Speedup                |
| -------------------- | ----------- | ----------- | ---------------------- |
| 128√ó256√ó512          | 22,490,484  | 22,656,767  | **0.99√ó** (identisch)  |
| 256√ó512√ó1024         | 242,206,333 | 311,439,500 | **0.78√ó** (langsamer?) |

**√úberraschung:** Bei gro√üen Matrizen ist die neue Variante hier _langsamer_.

**Ursache (Hypothese):**
- Fallback-Pfad (ohne BLAS) hat bei TN-Modus ung√ºnstige Cache-Access-Patterns
- Alte Variante: `sm_transpose(X)` erzeugt contiguous Zeilen ‚Üí besserer Cache-Hit bei anschlie√üendem `sm_multiply()`
- Neue Variante: direkte Indizierung `a[p * A->cols + i]` f√ºr Transponierung hat Stride-Access

**Empfehlung:** Mit BLAS/Accelerate aktiviert w√§re das anders (siehe unten).

---

### 3. Backprop-Muster: dX = dY √ó W^T (Transpose auf rechter Matrix)

| Gr√∂√üe (Batch√óOut√óIn) | ALT (ns)    | NEU (ns)    | Speedup     |
| -------------------- | ----------- | ----------- | ----------- |
| 128√ó512√ó256          | 20,380,000  | 13,757,627  | **1.48√ó** ‚úÖ |
| 256√ó1024√ó512         | 133,892,800 | 111,612,667 | **1.20√ó** ‚úÖ |

**Ergebnis:** **+20-48% Beschleunigung!** üöÄ

**Warum?**
- Alte Variante: `sm_transpose(W)` allokiert 256√ó1024 Matrix ‚Üí hoher Memory-Overhead
- Neue Variante: NT-Modus (B transponiert) hat bessere Locality im Fallback-Pfad
- Speichereinsparung: keine tempor√§re Transpose-Matrix

---

## Performance-Vergleich: BLAS vs. Fallback (Erwartung)

| Backend             | dW = X^T √ó dY | dX = dY √ó W^T | Kommentar                        |
| ------------------- | ------------- | ------------- | -------------------------------- |
| **OpenMP/NEON**     | 0.78-0.99√ó    | 1.20-1.48√ó ‚úÖ  | NT-Modus profitiert, TN leidet   |
| **BLAS/Accelerate** | ~1.5-2√ó ‚úÖ     | ~1.5-2√ó ‚úÖ     | Beide Modi optimal (cblas_sgemm) |

**Wichtig:** Die Ergebnisse sind f√ºr den **Fallback-Pfad** (OpenMP). Mit aktiviertem BLAS (`USE_ACCELERATE` oder `USE_OPENBLAS`) w√ºrden **beide Transpose-Modi** massiv profitieren, da:

- `cblas_sgemm(..., CblasTrans, ...)` intern optimiert ist
- Keine explizite Transpose-Allokation n√∂tig
- BLAS-Bibliothek nutzt SIMD/Cache-Blocking f√ºr alle Modi

---

## Zusammenfassung & Empfehlung

### ‚úÖ **Klare Vorteile** (bereits im Fallback-Modus)
1. **dX = dY √ó W^T**: **+20-48% schneller** ‚Üí direkter Gewinn f√ºr Backprop
2. **Speichereffizienz**: Keine tempor√§ren Transpose-Matrizen
3. **API-Klarheit**: Transpose-Flags vermeiden Allokationsfehler

### ‚ö†Ô∏è **Einschr√§nkung** (Fallback-Modus)
- **dW = X^T √ó dY**: Bei gro√üen Matrizen (256√ó512√ó1024) leicht langsamer (~22%)
- **Ursache**: Cache-ung√ºnstige Indizierung bei TN-Modus ohne BLAS

### üéØ **Empfehlung**
1. **Mit BLAS/Accelerate kompilieren** (`--define=USE_ACCELERATE=1` auf macOS):
   ```bash
   bazel build -c opt --define=USE_ACCELERATE=1 //share/google_benchmark:bench_sm_gemm_comparison
   ```
   ‚Üí Erwartbar: **beide Transpose-Modi ~1.5-2√ó schneller**

2. **Fallback-Pfad optimieren** (optional):
   - F√ºr TN-Modus: Block-Tiling hinzuf√ºgen (√§hnlich wie `sm_transpose()`)
   - Oder: Hybrid-Strategie (gro√üe TN ‚Üí tempor√§re Transpose; kleine TN ‚Üí direkter Index)

3. **Production-Use:**
   - F√ºr NN/NT: **GEMM ist jetzt optimal** (identisch/schneller)
   - F√ºr TN ohne BLAS: alte `sm_transpose()`-Variante erw√§gen (oder BLAS nutzen)

---

## N√§chste Schritte

- [ ] BLAS-Build testen (erwartbar: alle Modi schneller)
- [ ] Fallback TN-Modus mit Cache-Blocking optimieren
- [ ] Integration in `nm`-Modul (wenn vorhanden)
- [ ] Memory-Profile (Heap-Allokationen alt vs. neu)

